import asyncio
import os
import psycopg2
from urllib.parse import urlparse
from bs4 import BeautifulSoup
from datetime import datetime
from playwright.async_api import async_playwright
from psycopg2 import sql


def get_db_connection():
    db_url = os.getenv("DATABASE_URL")
    if not db_url:
        raise Exception("‚ùå DATABASE_URL –Ω–µ –∑–∞–¥–∞–Ω–∞ –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")

    # –î–æ–±–∞–≤–∏–º sslmode=require, –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
    if "sslmode" not in db_url:
        if "?" in db_url:
            db_url += "&sslmode=require"
        else:
            db_url += "?sslmode=require"

    try:
        conn = psycopg2.connect(db_url)
        print("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
        return conn
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –±–∞–∑–µ: {e}")
        return None


async def get_page_html(url: str) -> str:
    try:
        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)
            context = await browser.new_context(user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64)")
            page = await context.new_page()
            await page.goto(url)
            await page.wait_for_selector("div.item-card__info", timeout=15000)
            content = await page.content()
            await browser.close()
            return content
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —á–µ—Ä–µ–∑ Playwright: {e}")
        return ""


def create_table(conn):
    with conn.cursor() as cur:
        cur.execute("""
            CREATE TABLE IF NOT EXISTS kaspi_products (
                id SERIAL PRIMARY KEY,
                title TEXT,
                url TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        conn.commit()
    print("‚úÖ –¢–∞–±–ª–∏—Ü–∞ –ø—Ä–æ–≤–µ—Ä–µ–Ω–∞/—Å–æ–∑–¥–∞–Ω–∞")


def parse_products(html):
    soup = BeautifulSoup(html, "html.parser")
    cards = soup.select("div.item-card__info")

    if not cards:
        print("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ –∫–∞—Ä—Ç–æ—á–µ–∫ —Ç–æ–≤–∞—Ä–æ–≤")
        print("--- HTML –Ω–∞—á–∞–ª–æ ---")
        print(soup.prettify()[:3000])  # –ø–æ–∫–∞–∂–µ–º —á–∞—Å—Ç—å HTML
        print("--- HTML –∫–æ–Ω–µ—Ü ---")
        return []

    products = []
    for card in cards:
        name_tag = card.select_one(".item-card__name a")
        if name_tag:
            title = name_tag.get_text(strip=True)
            url = f"https://kaspi.kz{name_tag['href']}"
            products.append((title, url))
    return products


def save_to_db(conn, products):
    with conn.cursor() as cur:
        for title, url in products:
            cur.execute(
                "INSERT INTO kaspi_products (title, url) VALUES (%s, %s) ON CONFLICT DO NOTHING",
                (title, url)
            )
        conn.commit()
    print(f"‚úÖ –ü–∞—Ä—Å–µ—Ä –∑–∞–≤–µ—Ä—à—ë–Ω. –î–æ–±–∞–≤–ª–µ–Ω–æ –Ω–æ–≤—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤: {len(products)}")
    print(f"üïí –í—Ä–µ–º—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è: {datetime.now()}")


async def main():
    print(f"üî• –ü–∞—Ä—Å–µ—Ä –∑–∞–ø—É—Å—Ç–∏–ª—Å—è: {datetime.now()}")
    conn = get_db_connection()
    if not conn:
        return

    create_table(conn)

    url = "https://kaspi.kz/shop/c/shoes/?page=1"
    html = await get_page_html(url)
    if not html:
        conn.close()
        return

    products = parse_products(html)
    if products:
        save_to_db(conn, products)
    else:
        print("‚ö†Ô∏è –ó–∞–≤–µ—Ä—à–µ–Ω–æ –±–µ–∑ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤")

    conn.close()


if __name__ == "__main__":
    asyncio.run(main())
